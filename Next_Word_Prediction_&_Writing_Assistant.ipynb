{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b6d3c04a57a54a6a9b907f248abf52bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_401de5571560499bbabe8e8d5ebb03df",
              "IPY_MODEL_e9dc32674a444249bdaf970233e69898",
              "IPY_MODEL_6d03b60d2e5d45c19c6951b34fca9965"
            ],
            "layout": "IPY_MODEL_8edddfef72cc45dcb3674438f01595ad"
          }
        },
        "401de5571560499bbabe8e8d5ebb03df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3062a79418a44a209f101104a39f0cea",
            "placeholder": "​",
            "style": "IPY_MODEL_30a2a35d11df4f7ea123eb60a12f0481",
            "value": "Generating train split: "
          }
        },
        "e9dc32674a444249bdaf970233e69898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbaaa3ab5f494a9eb296fff4f7cebd7b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c160e18cab94b4e8245d6fe582033ea",
            "value": 1
          }
        },
        "6d03b60d2e5d45c19c6951b34fca9965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70a7821e62ce47ff9ab141a1ef73a447",
            "placeholder": "​",
            "style": "IPY_MODEL_d738805d4eda44d98d508680c4437d09",
            "value": " 5/0 [00:00&lt;00:00, 72.91 examples/s]"
          }
        },
        "8edddfef72cc45dcb3674438f01595ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3062a79418a44a209f101104a39f0cea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30a2a35d11df4f7ea123eb60a12f0481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbaaa3ab5f494a9eb296fff4f7cebd7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0c160e18cab94b4e8245d6fe582033ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70a7821e62ce47ff9ab141a1ef73a447": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d738805d4eda44d98d508680c4437d09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52c56060d0a6469eb849e174b46a4a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6558e9e36af443c1bf9a2975fc96b1bf",
              "IPY_MODEL_54232ae6ea7344bfa24f815be884ac14",
              "IPY_MODEL_3667881928564636b1edf79f16ccd652"
            ],
            "layout": "IPY_MODEL_5305de0e92eb48a894298f7b5987a1f8"
          }
        },
        "6558e9e36af443c1bf9a2975fc96b1bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_639f7222aa594b0d9a8a78514ff9a646",
            "placeholder": "​",
            "style": "IPY_MODEL_6a6f6b6f45d148a6b96cf417cfde0d0b",
            "value": "Map: 100%"
          }
        },
        "54232ae6ea7344bfa24f815be884ac14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8168021d95c442e89072e95e79dfb4b8",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83c3a05249fd43769bc5060806807873",
            "value": 5
          }
        },
        "3667881928564636b1edf79f16ccd652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c3e563a4ac34ca9acaf16fe50204182",
            "placeholder": "​",
            "style": "IPY_MODEL_e76bfea1b42140a9a762fd1ee6046f99",
            "value": " 5/5 [00:00&lt;00:00, 95.22 examples/s]"
          }
        },
        "5305de0e92eb48a894298f7b5987a1f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "639f7222aa594b0d9a8a78514ff9a646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a6f6b6f45d148a6b96cf417cfde0d0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8168021d95c442e89072e95e79dfb4b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83c3a05249fd43769bc5060806807873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c3e563a4ac34ca9acaf16fe50204182": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e76bfea1b42140a9a762fd1ee6046f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj1y_4tazVir",
        "outputId": "f99ef6e5-2cfa-473c-97be-f518f671335b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Environment ready — now upload or create your dataset in writewise/data/raw/\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Setup environment\n",
        "\n",
        "!pip install -q transformers datasets accelerate torch sentencepiece streamlit\n",
        "\n",
        "import os\n",
        "os.makedirs(\"writewise/data/raw\", exist_ok=True)\n",
        "os.makedirs(\"writewise/data/processed\", exist_ok=True)\n",
        "os.makedirs(\"writewise/models\", exist_ok=True)\n",
        "\n",
        "print(\"✅ Environment ready — now upload or create your dataset in writewise/data/raw/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Create / upload training data\n",
        "\n",
        "# Option A: Create a small sample dataset here\n",
        "\n",
        "sample_text = \"\"\"\n",
        "Artificial intelligence is transforming industries and society.\n",
        "Data science helps us understand patterns in complex data.\n",
        "Machine learning enables computers to learn from experience.\n",
        "Generative AI can create new ideas and automate creativity.\n",
        "Business leaders use data-driven insights for better decisions.\n",
        "\"\"\"\n",
        "\n",
        "with open(\"writewise/data/raw/sample.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(sample_text)\n",
        "\n",
        "print(\"✅ Sample dataset created at writewise/data/raw/sample.txt\")\n",
        "\n",
        "# Option B: You can upload your own text file(s) into writewise/data/raw/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMsRgV-hzbIi",
        "outputId": "cde7bfa1-1277-443f-9542-9a9df1928c1d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Sample dataset created at writewise/data/raw/sample.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Dataset preparation\n",
        "\n",
        "# Splits text into clean sentences (1 per line) for training\n",
        "\n",
        "import re, glob\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "input_dir = \"writewise/data/raw\"\n",
        "output_file = \"writewise/data/processed/train.txt\"\n",
        "\n",
        "all_lines = []\n",
        "for fpath in glob.glob(f\"{input_dir}/*.txt\"):\n",
        "    with open(fpath, encoding=\"utf-8\") as f:\n",
        "        raw = f.read()\n",
        "    for block in raw.splitlines():\n",
        "        block = block.strip()\n",
        "        if not block: continue\n",
        "        parts = re.split(r'(?<=[.!?])\\s+', block)\n",
        "        for p in parts:\n",
        "            p = clean_text(p)\n",
        "            if len(p.split()) >= 5:\n",
        "                all_lines.append(p)\n",
        "\n",
        "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    for line in all_lines:\n",
        "        f.write(line + \"\\n\")\n",
        "\n",
        "print(f\"✅ Prepared {len(all_lines)} training lines at {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O27b0efAzbMX",
        "outputId": "dcfddf26-5927-45e8-ff00-e648259304f2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Prepared 5 training lines at writewise/data/processed/train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Step 4: Fine-tune GPT-2 (small)\n",
        "# ============================================================\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "import torch, os\n",
        "\n",
        "# Disable Weights & Biases logging\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "train_file = \"writewise/data/processed/train.txt\"\n",
        "model_name = \"gpt2\"\n",
        "output_dir = \"writewise/models/writewise-gpt2\"\n",
        "\n",
        "# Load text dataset\n",
        "dataset = load_dataset(\"text\", data_files={\"train\": train_file})\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "def tokenize_fn(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, max_length=128)\n",
        "\n",
        "tokenized = dataset.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    save_strategy=\"no\",\n",
        "    logging_steps=10,\n",
        "    learning_rate=5e-5,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=[],  # 👈 disables wandb and other reporters\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.save_model(output_dir)\n",
        "print(\"✅ Model fine-tuned and saved to:\", output_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368,
          "referenced_widgets": [
            "b6d3c04a57a54a6a9b907f248abf52bb",
            "401de5571560499bbabe8e8d5ebb03df",
            "e9dc32674a444249bdaf970233e69898",
            "6d03b60d2e5d45c19c6951b34fca9965",
            "8edddfef72cc45dcb3674438f01595ad",
            "3062a79418a44a209f101104a39f0cea",
            "30a2a35d11df4f7ea123eb60a12f0481",
            "cbaaa3ab5f494a9eb296fff4f7cebd7b",
            "0c160e18cab94b4e8245d6fe582033ea",
            "70a7821e62ce47ff9ab141a1ef73a447",
            "d738805d4eda44d98d508680c4437d09",
            "52c56060d0a6469eb849e174b46a4a69",
            "6558e9e36af443c1bf9a2975fc96b1bf",
            "54232ae6ea7344bfa24f815be884ac14",
            "3667881928564636b1edf79f16ccd652",
            "5305de0e92eb48a894298f7b5987a1f8",
            "639f7222aa594b0d9a8a78514ff9a646",
            "6a6f6b6f45d148a6b96cf417cfde0d0b",
            "8168021d95c442e89072e95e79dfb4b8",
            "83c3a05249fd43769bc5060806807873",
            "6c3e563a4ac34ca9acaf16fe50204182",
            "e76bfea1b42140a9a762fd1ee6046f99"
          ]
        },
        "id": "YW2Dyz6IzbOn",
        "outputId": "4297db8e-dadd-43de-b7ba-be989aa54024"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6d3c04a57a54a6a9b907f248abf52bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52c56060d0a6469eb849e174b46a4a69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-826544583.py:43: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 50257}.\n",
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:01, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model fine-tuned and saved to: writewise/models/writewise-gpt2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Inference — Next-word prediction & text generation\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_dir = \"writewise/models/writewise-gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_dir)\n",
        "model.eval()\n",
        "if torch.cuda.is_available():\n",
        "    model.to(\"cuda\")\n",
        "\n",
        "def top_k_next_tokens(prompt, top_k=5):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {k:v.to(\"cuda\") for k,v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "    last_logits = logits[0, -1, :]\n",
        "    probs = F.softmax(last_logits, dim=-1)\n",
        "    topk = torch.topk(probs, top_k)\n",
        "    tokens = topk.indices.tolist()\n",
        "    return [(tokenizer.decode([t]).strip(), float(s)) for t,s in zip(tokens, topk.values)]\n",
        "\n",
        "def generate_text(prompt, max_new_tokens=40, temperature=0.8):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {k:v.to(\"cuda\") for k,v in inputs.items()}\n",
        "    output = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=True, temperature=temperature, top_k=50)\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "prompt = \"The future of artificial intelligence\"\n",
        "print(\"Top next-word suggestions:\")\n",
        "for tok,score in top_k_next_tokens(prompt, top_k=5):\n",
        "    print(f\"{tok}  ({score:.4f})\")\n",
        "\n",
        "print(\"\\nGenerated continuation:\")\n",
        "print(generate_text(prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYbIH5uNzbQN",
        "outputId": "7d92e467-689c-4231-e204-bfda16b3e65b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top next-word suggestions:\n",
            "is  (0.3073)\n",
            "will  (0.0631)\n",
            "and  (0.0556)\n",
            ",  (0.0546)\n",
            "may  (0.0363)\n",
            "\n",
            "Generated continuation:\n",
            "The future of artificial intelligence? It depends on how many ways we use it.\n",
            "\n",
            "The most obvious possibility is to improve AI with software improvements. One idea is to improve on a computer's human language processing capabilities. For\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"34VADzTWUIxvmMrGEBiy0GsBBE5_2kGou76Cb1qvHrSJy2koL\")\n"
      ],
      "metadata": {
        "id": "pDVnqZsm-4lW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 6: Streamlit demo inside Colab\n",
        "# Note: Streamlit runs on a separate port — we’ll use `pyngrok` to tunnel it.\n",
        "\n",
        "!pip install -q pyngrok\n",
        "from pyngrok import ngrok\n",
        "import threading, time\n",
        "\n",
        "# Create app.py\n",
        "app_code = '''\n",
        "import streamlit as st\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "st.set_page_config(page_title=\"WriteWise — Next-Word Assistant\")\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model(model_dir=\"writewise/models/writewise-gpt2\"):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_dir)\n",
        "    model.eval()\n",
        "    if torch.cuda.is_available():\n",
        "        model.to(\"cuda\")\n",
        "    return tokenizer, model\n",
        "\n",
        "tokenizer, model = load_model()\n",
        "\n",
        "def top_k_next_tokens(prompt, top_k=5):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {k:v.to(\"cuda\") for k,v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "    last_logits = logits[0, -1, :]\n",
        "    probs = torch.nn.functional.softmax(last_logits, dim=-1)\n",
        "    topk = torch.topk(probs, top_k)\n",
        "    tokens = topk.indices.tolist()\n",
        "    return [(tokenizer.decode([t]).strip(), float(s)) for t,s in zip(tokens, topk.values)]\n",
        "\n",
        "def generate_text(prompt, max_new_tokens=50, temperature=0.8):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {k:v.to(\"cuda\") for k,v in inputs.items()}\n",
        "    output = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=True, temperature=temperature, top_k=50)\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "st.title(\"WriteWise — Next-Word Prediction & Text Generator\")\n",
        "prompt = st.text_area(\"Enter your prompt:\", \"The future of AI is\")\n",
        "\n",
        "col1, col2 = st.columns(2)\n",
        "with col1:\n",
        "    if st.button(\"Next-Word Suggestions\"):\n",
        "        results = top_k_next_tokens(prompt, 5)\n",
        "        for w,p in results:\n",
        "            st.write(f\"**{w}**  ({p:.4f})\")\n",
        "with col2:\n",
        "    if st.button(\"Generate Text\"):\n",
        "        out = generate_text(prompt, 60, 0.8)\n",
        "        st.write(out)\n",
        "'''\n",
        "\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "# Launch Streamlit app\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Streamlit public URL:\", public_url)\n",
        "!streamlit run app.py --server.port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXkdBqQlzbSD",
        "outputId": "e81d7df0-74df-4bac-e866-60c121335e05"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit public URL: NgrokTunnel: \"https://astronomical-kohen-treasurable.ngrok-free.dev\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.143.149.124:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2025-10-24 07:04:49.653706: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761289489.674777   10382 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761289489.681400   10382 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761289489.700712   10382 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761289489.700760   10382 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761289489.700767   10382 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761289489.700772   10382 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "c\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}